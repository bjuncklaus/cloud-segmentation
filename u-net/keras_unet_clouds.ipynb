{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lpEMXhyJ4Xb3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ir-p6L7zeXeu"
   },
   "outputs": [],
   "source": [
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_LQsB64yqOt_"
   },
   "outputs": [],
   "source": [
    "seed = 99\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "IMG_WIDTH = 224\n",
    "IMG_HEIGHT = IMG_WIDTH\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "IMAGES_PATH = 'images/'\n",
    "MASKS_PATH = 'GTmaps/''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dKEyx_XlqYAJ"
   },
   "outputs": [],
   "source": [
    "train_ratio = .8\n",
    "test_ratio = .2\n",
    "\n",
    "total_images = len(os.listdir(IMAGES_PATH))\n",
    "\n",
    "train_size = int(total_images * train_ratio)\n",
    "test_size = int(total_images * test_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9fHd6UMHuDP7"
   },
   "outputs": [],
   "source": [
    "image_ids = os.listdir(IMAGES_PATH)\n",
    "\n",
    "train_image_ids = random.sample(image_ids, train_size)\n",
    "train_mask_ids = [id.replace('.png', '_GT.png') for id in train_image_ids]\n",
    "\n",
    "image_ids = [id for id in image_ids if id not in train_image_ids]\n",
    "\n",
    "test_image_ids = image_ids\n",
    "test_mask_ids = [id.replace('.png', '_GT.png') for id in test_image_ids]\n",
    "\n",
    "assert len(os.listdir(IMAGES_PATH)) == len(train_image_ids) + len(test_image_ids) == len(train_mask_ids) + len(test_mask_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sZP7LTjg0MfS"
   },
   "source": [
    "## Sanity check for images and masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gvs-pe8ZyMso"
   },
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(imread(IMAGES_PATH + train_image_ids[0])[:,:,:IMG_CHANNELS])\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(imread(MASKS_PATH + train_mask_ids[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wyabtYQMyM_H"
   },
   "outputs": [],
   "source": [
    "X_train = np.zeros((len(train_image_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "Y_train = np.zeros((len(train_image_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "\n",
    "X_test = np.zeros((len(test_image_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "Y_test = np.zeros((len(test_image_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lGeuqub5yNBt"
   },
   "outputs": [],
   "source": [
    "def read_resized_images(path, ids, channels, data):\n",
    "  for n, id_ in enumerate(ids):\n",
    "    if (channels):\n",
    "      image = imread(path + id_)[:,:,:channels]\n",
    "      data[n] = resize(image, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    else:\n",
    "      image = imread(path + id_)\n",
    "      data[n] = np.expand_dims(resize(image, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LZ6r3q2KB5KR"
   },
   "outputs": [],
   "source": [
    "read_resized_images(IMAGES_PATH, train_image_ids, IMG_CHANNELS, X_train)\n",
    "read_resized_images(MASKS_PATH, train_mask_ids, None, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T7FsTlXSDb7Y"
   },
   "outputs": [],
   "source": [
    "read_resized_images(IMAGES_PATH, test_image_ids, IMG_CHANNELS, X_test)\n",
    "read_resized_images(MASKS_PATH, test_mask_ids, None, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MZbe8TcgEdkD"
   },
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JO5i4M72EG8r"
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "input = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AqJcN3YvYArL"
   },
   "outputs": [],
   "source": [
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "# activation = LeakyReLU()\n",
    "activation = 'relu'\n",
    "# activation = 'tanh'\n",
    "# activation = 'selu'\n",
    "kernel_initializer = 'he_normal'\n",
    "padding = 'same'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "trZWxLR6Eu8G"
   },
   "source": [
    "## Contraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k96XEXVIowbl"
   },
   "source": [
    "The following code was adapted from [here](https://github.com/bnsreenu/python_for_microscopists)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3mULja4BqH-u"
   },
   "outputs": [],
   "source": [
    "c1 = tf.keras.layers.Conv2D(16, (3, 3), activation=activation, kernel_initializer=kernel_initializer, padding=padding)(input)\n",
    "c1 = tf.keras.layers.Dropout(0.2)(c1)\n",
    "# c1 = tf.keras.layers.Conv2D(16, (3, 3), activation=activation, kernel_initializer=kernel_initializer, padding=padding)(c1)\n",
    "p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "c2 = tf.keras.layers.Conv2D(32, (3, 3), activation=activation, kernel_initializer=kernel_initializer, padding=padding)(p1)\n",
    "c2 = tf.keras.layers.Dropout(0.2)(c2)\n",
    "# c2 = tf.keras.layers.Conv2D(32, (3, 3), activation=activation, kernel_initializer=kernel_initializer, padding=padding)(c2)\n",
    "p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
    " \n",
    "c3 = tf.keras.layers.Conv2D(64, (3, 3), activation=activation, kernel_initializer=kernel_initializer, padding=padding)(p2)\n",
    "c3 = tf.keras.layers.Dropout(0.2)(c3)\n",
    "# c3 = tf.keras.layers.Conv2D(64, (3, 3), activation=activation, kernel_initializer=kernel_initializer, padding=padding)(c3)\n",
    "p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
    " \n",
    "c4 = tf.keras.layers.Conv2D(128, (3, 3), activation=activation, kernel_initializer=kernel_initializer, padding=padding)(p3)\n",
    "c4 = tf.keras.layers.Dropout(0.2)(c4)\n",
    "# c4 = tf.keras.layers.Conv2D(128, (3, 3), activation=activation, kernel_initializer=kernel_initializer, padding=padding)(c4)\n",
    "p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n",
    " \n",
    "c5 = tf.keras.layers.Conv2D(256, (3, 3), activation=activation, kernel_initializer=kernel_initializer, padding=padding)(p4)\n",
    "c5 = tf.keras.layers.Dropout(0.2)(c5)\n",
    "c5 = tf.keras.layers.Conv2D(256, (3, 3), activation=activation, kernel_initializer=kernel_initializer, padding=padding)(c5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_KhhVzoYE9J2"
   },
   "source": [
    "## Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TazLIxKlqWSy"
   },
   "outputs": [],
   "source": [
    "u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding=padding)(c5)\n",
    "u6 = tf.keras.layers.concatenate([u6, c4])\n",
    "c6 = tf.keras.layers.Conv2D(128, (3, 3), activation=activation, kernel_initializer=kernel_initializer, padding=padding)(u6)\n",
    "c6 = tf.keras.layers.Dropout(0.2)(c6)\n",
    "# c6 = tf.keras.layers.Conv2D(128, (3, 3), activation=activation, kernel_initializer=kernel_initializer, padding=padding)(c6)\n",
    " \n",
    "u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding=padding)(c6)\n",
    "u7 = tf.keras.layers.concatenate([u7, c3])\n",
    "c7 = tf.keras.layers.Conv2D(64, (3, 3), activation=activation, kernel_initializer=kernel_initializer, padding=padding)(u7)\n",
    "c7 = tf.keras.layers.Dropout(0.2)(c7)\n",
    "# c7 = tf.keras.layers.Conv2D(64, (3, 3), activation=activation, kernel_initializer=kernel_initializer, padding=padding)(c7)\n",
    " \n",
    "u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding=padding)(c7)\n",
    "u8 = tf.keras.layers.concatenate([u8, c2])\n",
    "c8 = tf.keras.layers.Conv2D(32, (3, 3), activation=activation, kernel_initializer=kernel_initializer, padding=padding)(u8)\n",
    "c8 = tf.keras.layers.Dropout(0.2)(c8)\n",
    "# c8 = tf.keras.layers.Conv2D(32, (3, 3), activation=activation, kernel_initializer=kernel_initializer, padding=padding)(c8)\n",
    " \n",
    "u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding=padding)(c8)\n",
    "u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\n",
    "c9 = tf.keras.layers.Conv2D(16, (3, 3), activation=activation, kernel_initializer=kernel_initializer, padding=padding)(u9)\n",
    "c9 = tf.keras.layers.Dropout(0.2)(c9)\n",
    "# c9 = tf.keras.layers.Conv2D(16, (3, 3), activation=activation, kernel_initializer=kernel_initializer, padding=padding)(c9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MmkROa3uFAIQ"
   },
   "source": [
    "## Fully Connected Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-98dE4EkEHBm"
   },
   "outputs": [],
   "source": [
    "outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ik1KvMcEFK3g"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "irNJwZbPK76L"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2.0 * intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xvIFJ9p0EG_n"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xat2gvKpvuYf"
   },
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5olgCe7bFY-O"
   },
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ITUtgSivFRFG"
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "        tf.keras.callbacks.TensorBoard(log_dir='tensorboard'),\n",
    "        tf.keras.callbacks.EarlyStopping(patience=5, monitor='val_loss'),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(),\n",
    "        tf.keras.callbacks.ModelCheckpoint('models/best_model.h5', monitor='val_loss', mode='auto', verbose=1, save_best_only=True)\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wq6vRGPrFuI0"
   },
   "source": [
    "## Training\n",
    "**Note**: Keras splits the validation data as follows: \"The validation data is selected from the **last samples** in the x and y data provided, before shuffling.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SlTUNwjwn3DC"
   },
   "outputs": [],
   "source": [
    "!rm -rf \"tensorboard\"\n",
    "results = model.fit(X_train, Y_train, validation_split=0.1, batch_size=8, epochs=100, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fnucr0W-NBqf"
   },
   "source": [
    "## Splitting Validation Data\n",
    "**Note**: Since Keras splits the data for validation from the last samples provided I'm splitting the data in the same manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NPUgSuZ1FRde"
   },
   "outputs": [],
   "source": [
    "idx = random.randint(0, len(X_train))\n",
    "\n",
    "preds_train = model.predict(X_train[:int(X_train.shape[0]*0.9)], verbose=1)\n",
    "preds_val = model.predict(X_train[int(X_train.shape[0]*0.9):], verbose=1)\n",
    "preds_test = model.predict(X_test, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dbUP4wvhNfb1"
   },
   "source": [
    "## Setting Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "URlmYeb_FRbg"
   },
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "preds_train_t = (preds_train > threshold).astype(np.uint8)\n",
    "preds_val_t = (preds_val > threshold).astype(np.uint8)\n",
    "preds_test_t = (preds_test > threshold).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2jZPvxZUFRV0"
   },
   "outputs": [],
   "source": [
    "# Perform a sanity check on some random training samples\n",
    "rows = 1\n",
    "cols = 3\n",
    "plt.figure(figsize=(16,8))\n",
    "\n",
    "for i in range(1, rows*cols, 3):\n",
    "  ix = random.randint(0, len(preds_train_t))\n",
    "  plt.subplot(rows, cols, i)\n",
    "  imshow(X_train[ix])\n",
    "  plt.subplot(rows, cols, i+1)\n",
    "  imshow(np.squeeze(Y_train[ix]))\n",
    "  plt.subplot(rows, cols, i+2)\n",
    "  imshow(np.squeeze(preds_train_t[ix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VWfeto59FRT0"
   },
   "outputs": [],
   "source": [
    "# Perform a sanity check on some random validation samples\n",
    "ix = random.randint(0, len(preds_val_t))\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.subplot(1, 3, 1)\n",
    "imshow(X_train[int(X_train.shape[0]*0.9):][ix])\n",
    "plt.subplot(1, 3, 2)\n",
    "imshow(np.squeeze(Y_train[int(Y_train.shape[0]*0.9):][ix]))\n",
    "plt.subplot(1, 3, 3)\n",
    "imshow(np.squeeze(preds_val_t[ix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SZ49fPMBP6_s"
   },
   "outputs": [],
   "source": [
    "# Perform a sanity check on some random test samples\n",
    "ix = random.randint(0, len(preds_test_t))\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.subplot(1, 3, 1)\n",
    "imshow(X_test[ix])\n",
    "plt.subplot(1, 3, 2)\n",
    "imshow(np.squeeze(Y_test[ix]))\n",
    "plt.subplot(1, 3, 3)\n",
    "imshow(np.squeeze(preds_test_t[ix]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oijDW4CdxDzU"
   },
   "outputs": [],
   "source": [
    "!kill 8819"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X0bs6XNKFRMg"
   },
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir {\"tensorboard\"}"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "keras_unet_clouds.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
